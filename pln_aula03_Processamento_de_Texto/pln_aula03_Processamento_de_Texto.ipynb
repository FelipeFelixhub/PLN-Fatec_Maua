{"cells":[{"cell_type":"markdown","metadata":{"id":"ob-aTmc0vI3P"},"source":["# **Aula 03** - Processamento de Texto e Pr√©-processamento de Dados\n","\n","O pr√©-processamento limpa e transforma esse texto para facilitar o trabalho do algoritmo, deixando s√≥ as informa√ß√µes relevantes. T√©cnicas de Pr√©-processamento de Texto:\n","1. **Normaliza√ß√£o de Texto** - Ajusta do texto para ter uma grafia padronizada;\n","2. **Remo√ß√£o de Ru√≠do** - Retirar elementos do texto que n√£o agregam valor √† an√°lise e podem atrapalhar;\n","3. **Tokeniza√ß√£o** - Tokenizar √© dividir o texto em pequenas unidades;\n","4. **Remo√ß√£o de Stopwords** - Remover palavras que n√£o carregam muito significado para an√°lise;\n","5. **Stemming** - T√©cnica para reduzir palavras √†s suas ra√≠zes ou radicais, cortando sufixos e prefixos;\n","6. **Lematiza√ß√£o** - Redu√ß√£o da palavra √† sua forma de dicion√°rio (forma can√¥nica)\n"]},{"cell_type":"markdown","metadata":{"id":"j_dIXOsQPgWM"},"source":["## 1. Normaliza√ß√£o de texto e Remo√ß√£o de Ru√≠do\n","* Remover caracteres especiais, pontua√ß√µes, e normalizar o uso de letras mai√∫sculas e min√∫sculas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jt_ATgeaRd5t"},"outputs":[],"source":[" # importa a biblioteca para trabalhar com express√µes regulares\n","import re\n","\n","original = \"Ol√°!!! Este √© um exemplo de texto, com v√°rias PONTUA√á√ïES, s√≠mbolos #especiais, e LETRAS mai√∫sculas.\"\n","\n","texto_limpo = re.sub(r'[^A-Za-z√Ä-√ø\\s]', '',original)\n","  # re.sub() fun√ß√£o que realiza substitui√ß√£o\n","  # r'[^A-Za-z√Ä-√ø\\s]'>>> express√£o regular que define um conjunto de caracteres a serem removidos\n","    # [A-Za-z√Ä-√ø\\s] >>> define um conjunto de caracteres de A at√© Z, a at√© z e acentos e espa√ßos\n","    # ^faz a nega√ß√£o de uma express√£o regular\n","  # '' substitui a express√£o regular por uma string vazia\n","\n","texto_normalizado = texto_limpo.lower()\n","\n","print(f'Texto original: {original}')\n","print(f'\\nTexto limpo: {texto_limpo}')\n","print(f'\\nTexto normalizado: {texto_normalizado}')"]},{"cell_type":"markdown","metadata":{"id":"jYp-83H4RQqm"},"source":["## 2. Tokeniza√ß√£o\n","* Tokeniza√ß√£o √© dividir o texto em unidades menores (tokens), que geralmente s√£o palavras ou pontua√ß√µes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xm82-3Kszl3o"},"outputs":[],"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","\n","#nltk.download('punkt_tab')\n","\n","tokens = word_tokenize(texto_normalizado)\n","\n","print(f'Texto original: {original}')\n","print(f'\\n\\nTexto limpo: {texto_limpo}')\n","print(f'\\n\\nTexto normalizado: {texto_normalizado}')\n","print(f'\\n\\nTokens extraidos: {tokens}\\n')"]},{"cell_type":"markdown","metadata":{"id":"HpgD9AEz_Ndf"},"source":["## 3. Remo√ß√£o de Stopwords\n","* Stopwords s√£o palavras de pouco valor sem√¢ntico (como \"de\", \"a\", \"o\") que podem ser removidas para simplificar o texto\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"WoR5qEzeLYe4"},"outputs":[],"source":["from nltk.corpus import stopwords\n","\n","nltk.download('stopwords')\n","\n","stopwords_pt = set(stopwords.words('portuguese'))\n","\n","print(stopwords_pt)\n","\n","tokens_sem_stopwords = [palavra for palavra in tokens if palavra.lower() not in stopwords_pt]\n","\n","print(f'\\n\\nTokens extraidos: {tokens} + \\n quantidade de tokens: {len(tokens)}')\n","print(f'\\n\\nTokens extraidos: {tokens_sem_stopwords} + \\n quantidade de tokens: {len(tokens_sem_stopwords)}\\n')"]},{"cell_type":"markdown","metadata":{"id":"aQD3wA6WNGkj"},"source":["## 4. Stemming e Lemaliza√ß√£o\n","\n","\n","*   Stemming reduz as palavras √†s suas ra√≠zes (ou radicais);\n","*   Lematiza√ß√£o normaliza as palavras para suas formas base, levando em conta contexto e gram√°tica."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0sodbs3zNsme"},"outputs":[],"source":["from nltk.stem import RSLPStemmer\n","\n","nltk.download('rslp')\n","\n","stemmer = RSLPStemmer()\n","stemming = [stemmer.stem(palavra) for palavra in tokens_sem_stopwords]\n","print(f'\\n\\nTokens extraidos: {tokens_sem_stopwords}')\n","print(f'\\n\\nTokens radicais: {stemming}\\n\\n\\n')"]},{"cell_type":"markdown","metadata":{"id":"DBOpfgbqaCXj"},"source":["## 5. Exemplo 01 - Pr√© Processamento completo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XwI--WhdaElD"},"outputs":[],"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","import re\n","\n","# Download dos recursos do NLTK (se necess√°rio)\n","#nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","# Texto de exemplo\n","texto = input(\"Insira um texto que seja coerente, podendo ter s√≠mbolos: \")\n","\n","# Limpeza de ru√≠dos e normaliza√ß√£o\n","texto_limpo = re.sub(r'[^a-zA-Z]', ' ', texto)  # Remove tudo que n√£o for letra e substitui por espa√ßo\n","texto_lower = texto_limpo.lower()  # Converte para min√∫sculas\n","\n","# Tokeniza√ß√£o\n","tokens = nltk.word_tokenize(texto_lower)\n","\n","# Remo√ß√£o de stopwords\n","stop_words = set(stopwords.words('portuguese'))\n","palavras_filtradas = [palavra for palavra in tokens if palavra not in stop_words]\n","\n","# Stemming\n","stemmer = PorterStemmer()\n","palavras_stemizadas = [stemmer.stem(palavra) for palavra in palavras_filtradas]\n","\n","# Impress√£o do resultado final\n","print(palavras_stemizadas)"]},{"cell_type":"markdown","metadata":{"id":"Y6wOjBcII01r"},"source":["## Exemplo 02 - Estrutura de Pr√©-processamento de texto\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"__DaZAOTJrqa"},"outputs":[],"source":["!pip install spacy\n","!python -m spacy download pt_core_news_sm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jn9KnCANJJZq"},"outputs":[],"source":["import re\n","import spacy\n","import nltk\n","from nltk.corpus import stopwords\n","import string\n","\n","\n","# Baixar stopwords do NLTK (se necess√°rio)\n","nltk.download('stopwords')\n","nltk.download('punkt_tab')\n","nltk.download('wordnet')\n","nltk.download('rslp')\n","\n","# Carregar modelo do spaCy (portugu√™s como exemplo, pode trocar para 'en_core_web_sm' se for ingl√™s)\n","nlp = spacy.load(\"pt_core_news_sm\")\n","\n","# Texto de exemplo (pode ser uma review ou trecho de not√≠cia)\n","texto = \"O Processamento de Linguagem Natural (PLN) √© uma √°rea essencial da intelig√™ncia artificial! üòä Confira mais em: https://exemplo.com\"\n","\n","# 1. Normaliza√ß√£o (remover acentos, transformar em min√∫sculas, etc.)\n","def normalizar_texto(texto):\n","    texto = texto.lower()\n","    texto = re.sub(r'https?://\\S+|www\\.\\S+', '', texto)  # Remover URLs\n","    texto = re.sub(r'[^a-zA-Z√°-√∫√Å-√ö√ß√á ]', '', texto)     # Remover caracteres especiais (ajuste para outros idiomas)\n","    return texto\n","\n","texto_normalizado = normalizar_texto(texto)\n","\n","# 2. Tokeniza√ß√£o (nltk)\n","tokens = nltk.word_tokenize(texto_normalizado, language='portuguese')\n","\n","# 3. Remo√ß√£o de stopwords (nltk)\n","stopwords_pt = set(stopwords.words('portuguese'))\n","tokens_sem_stopwords = [token for token in tokens if token not in stopwords_pt]\n","\n","# 4. Stemming (nltk)\n","stemmer = nltk.RSLPStemmer()\n","tokens_stem = [stemmer.stem(token) for token in tokens_sem_stopwords]\n","\n","# 5. Lematiza√ß√£o (spaCy)\n","def lematizar_com_spacy(tokens):\n","    doc = nlp(\" \".join(tokens))\n","    return [token.lemma_ for token in doc]\n","\n","tokens_lematizados = lematizar_com_spacy(tokens_sem_stopwords)\n","\n","# 6. Compara√ß√£o\n","print(\"Texto Original:\\n\", texto)\n","print(\"\\nTexto Normalizado:\\n\", texto_normalizado)\n","print(\"\\nTokens:\\n\", tokens)\n","print(\"\\nTokens Sem Stopwords:\\n\", tokens_sem_stopwords)\n","print(\"\\nStemming:\\n\", tokens_stem)\n","print(\"\\nLematiza√ß√£o:\\n\", tokens_lematizados)\n"]},{"cell_type":"markdown","metadata":{"id":"BhR6r6quLNw6"},"source":["## Exemplo 03 - O modelo pre treinado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wpTtoqtJLF-d"},"outputs":[],"source":["import spacy\n","\n","# Carregar o modelo para portugu√™s\n","nlp = spacy.load(\"pt_core_news_sm\")\n","\n","# Processar um texto em portugu√™s\n","textoRecebido = input(\"Digite um texto para ser analisado: \")\n","doc = nlp(textoRecebido)\n","\n","print('\\nAn√°lise gramatical das palavras:')\n","for token in doc:\n","    print(f\"Palavra: {token.text}, Classe: {token.pos_}\")\n","\n","print(\"\\nAnalise de Depend√™ncias:\")\n","for token in doc:\n","  print(f\"Palavra: {token.text}, Depende de: {token.head.text}\")\n","\n","# Visualizar a √°rvore graficamente (opcional)\n","from spacy import displacy\n","displacy.render(doc, style=\"dep\", jupyter=True)"]},{"cell_type":"markdown","metadata":{"id":"5XnRfVt6LaIk"},"source":["* O que s√£o: Conjuntos de dados estat√≠sticos e regras, Treinados com milh√µes de textos, Especializados em tarefas espec√≠ficas de linguagem, Resultado de aprendizado de m√°quina\n","* Como s√£o treinados: Alimentados com grande volume de textos, Aprendem padr√µes do idioma, Reconhecem estruturas gramaticais, Identificam rela√ß√µes entre palavras, S√£o testados e refinados\n","* Tipos de modelos por tamanho:\n","  * Pequeno (sm): Mais r√°pido, menor precis√£o, Usa menos mem√≥ria, Bom para testes\n","  * M√©dio (md): Equil√≠brio entre velocidade e precis√£o, Precis√£o moderada\n","Bom para uso geral\n","  * Grande (lg): Mais preciso, Mais lento, Usa mais mem√≥ria, Melhor para an√°lises detalhadas\n","* Alguns modelos pr√©-treinados:\n","  * Portugu√™s - nlp_pt = spacy.load('pt_core_news_sm')\n","  * Ingl√™s - nlp_en = spacy.load('en_core_web_sm')\n","  * Espanhol - nlp_es = spacy.load('es_core_news_sm')\n","  * Franc√™s - nlp_fr = spacy.load('fr_core_news_sm')\n","  * Alem√£o - nlp_de = spacy.load('de_core_news_sm')\n"]}],"metadata":{"colab":{"collapsed_sections":["j_dIXOsQPgWM","jYp-83H4RQqm","HpgD9AEz_Ndf","aQD3wA6WNGkj","DBOpfgbqaCXj"],"provenance":[{"file_id":"1fFnLB7px9faJgtfxJMjbetrtUW8FNvMZ","timestamp":1743805376654}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}